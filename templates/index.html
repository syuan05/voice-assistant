<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <title>èªéŸ³æ€¥æ•‘åŠ©æ‰‹</title>
  <style>
    body { font-family: sans-serif; padding: 20px; background-color: #f5f5f5; }
    #chatbox { max-width: 600px; margin: auto; background: white; padding: 20px; border-radius: 10px; }
    .msg { margin: 10px 0; padding: 10px; border-radius: 8px; max-width: 80%; }
    .user { background: #dcf8c6; align-self: flex-end; text-align: right; margin-left: auto; }
    .ai { background: #e8e8e8; align-self: flex-start; }
    #chat { display: flex; flex-direction: column; }
    #micBtn { margin-top: 20px; }
  </style>
</head>
<body>
  <div id="chatbox">
    <h2>ğŸ©º èªéŸ³æ€¥æ•‘åŠ©æ‰‹</h2>
    <div id="chat"></div>
    <button id="micBtn" onclick="startListening()">ğŸ¤ é–‹å§‹èªªè©±</button>
  </div>

  <script>
    const synth = window.speechSynthesis;
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'zh-TW';

    const chat = document.getElementById("chat");

    // è¼¸å‡ºè¨Šæ¯
    function appendMessage(text, sender) {
      const msg = document.createElement("div");
      msg.className = "msg " + sender;
      msg.textContent = text;
      chat.appendChild(msg);
      chat.scrollTop = chat.scrollHeight;
    }

    // è¬›è©±æ™‚åœæ­¢æ’­æ”¾è²éŸ³ï¼Œé–‹å§‹è¾¨è­˜
    function startListening() {
      synth.cancel(); // â›” åœæ­¢ AI è¬›è©±
      recognition.start();
      appendMessage("ï¼ˆæ­£åœ¨è½ä½ èªªè©±...ï¼‰", "user");
    }

    recognition.onresult = function(event) {
      const transcript = event.results[0][0].transcript;
      document.querySelector(".user:last-child").textContent = transcript;
      sendToServer(transcript);
    };

    function sendToServer(text) {
      fetch("/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message: text })
      })
      .then(res => res.json())
      .then(data => {
        const reply = data.response;
        appendMessage(reply, "ai");
        speak(reply);
      })
      .catch(err => {
        appendMessage("âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼Œç„¡æ³•å–å¾—å›æ‡‰ã€‚", "ai");
      });
    }

    function speak(text) {
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = 'zh-TW';

      // âœ… é¸æ“‡ç¹é«”ä¸­æ–‡èªéŸ³ï¼ˆè‹¥æœ‰ï¼‰
      const voice = synth.getVoices().find(v => v.lang === 'zh-TW');
      if (voice) utter.voice = voice;

      synth.speak(utter);
    }

    // ä¸»å‹•æ­¡è¿è©ï¼ˆéœ€ç­‰èªéŸ³è¼‰å…¥ï¼‰
    window.onload = () => {
      synth.onvoiceschanged = () => {
        const welcome = "æˆ‘æ˜¯æ€¥æ•‘åŠ©æ‰‹ï¼Œè«‹å•ç¾åœ¨ç™¼ç”Ÿä»€éº¼æƒ…æ³ï¼Ÿ";
        appendMessage(welcome, "ai");
        speak(welcome);
      };
    };
  </script>
</body>
</html>
